{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3Nuf-G4xJ0u"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "id": "zZ81_4tLxSvd"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNBP_f0QUTfO"
   },
   "source": [
    "# Getting started with [TensorBoard.dev](https://tensorboard.dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLXZ3t1PWdOp"
   },
   "source": [
    "[TensorBoard.dev](https://tensorboard.dev) is a free, public [TensorBoard](https://tensorflow.org/tensorboard) service that enables you to upload and share your ML experiments with everyone.\n",
    "\n",
    "This notebook trains a simple model and shows how to upload the logs to TensorBoard.dev. [Preview](https://tensorboard.dev/experiment/rldGbR8rRHeCEbkK61SWTQ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjBn-ptXTppA"
   },
   "source": [
    "### Setup and imports\n",
    "\n",
    "This notebook uses TensorBoard features which are only available for versions >= `2.3.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L3ns52Luracm"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqUABmUTT1Cl"
   },
   "source": [
    "### Train a simple model and create TensorBoard logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LZExSr2Qrc5S"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSv4C0dBrmAx"
   },
   "source": [
    "TensorBoard logs are created during training by passing the [TensorBoard](https://www.tensorflow.org/tensorboard/get_started) and [hyperparameters callbacks](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) to Keras' Model.fit(). These logs can then be uploaded to TensorBoard.dev.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dsVjm5CrUtXm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "hparams Keras callback only supported in TensorFlow eager mode",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\APIDWA~1\\AppData\\Local\\Temp/ipykernel_3060/2691186275.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     callbacks=[tensorboard_callback, hparams_callback])\n\u001b[0m",
      "\u001b[1;32mc:\\users\\apidwalin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\apidwalin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\apidwalin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m   \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m   \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m   \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\apidwalin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_begin_hook\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;34m\"\"\"Helper function for on_{train|test|predict}_begin methods.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\apidwalin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \"\"\"\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\apidwalin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\plugins\\hparams\\keras.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mlogs\u001b[0m  \u001b[1;31m# unused\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[0msummary_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\apidwalin\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorboard\\plugins\\hparams\\keras.py\u001b[0m in \u001b[0;36m_get_writer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             raise RuntimeError(\n\u001b[1;32m---> 84\u001b[1;33m                 \u001b[1;34m\"hparams Keras callback only supported in TensorFlow eager mode\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             )\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: hparams Keras callback only supported in TensorFlow eager mode"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir, histogram_freq=1)\n",
    "hparams_callback = hp.KerasCallback(log_dir, {\n",
    "    'num_relu_units': 512,\n",
    "    'dropout': 0.2\n",
    "})\n",
    "\n",
    "model.fit(\n",
    "    x=x_train, \n",
    "    y=y_train, \n",
    "    epochs=5, \n",
    "    validation_data=(x_test, y_test), \n",
    "    callbacks=[tensorboard_callback, hparams_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TgF35qdzIC3T"
   },
   "source": [
    "### (Jupyter only)  Authorize TensorBoard.dev\n",
    "\n",
    "**This step is not necessary in Colab**\n",
    "\n",
    "This step requires you to auth in your shell console, outside of Jupyter.  In your console, execute the following command.\n",
    "\n",
    "`tensorboard dev list`\n",
    "\n",
    "As part of this flow, you will be provided with an authorization code. This code is required to consent to the Terms of Service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKW8V5chyx6e"
   },
   "source": [
    "### Upload to TensorBoard.dev\n",
    "\n",
    "Uploading the TensorBoard logs will give you a URL that can be shared with anyone.\n",
    "\n",
    "Uploaded TensorBoards are public, so do not upload sensitive data.\n",
    "\n",
    "The uploader will exit when the entire logdir has uploaded.  (This is what the `--one_shot` flag specifies.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2PvxhOkW7vn"
   },
   "outputs": [],
   "source": [
    "!tensorboard dev upload --logdir ./logs \\\n",
    "  --name \"Simple experiment with MNIST\" \\\n",
    "  --description \"Training results from https://colab.sandbox.google.com/github/tensorflow/tensorboard/blob/master/docs/tbdev_getting_started.ipynb\" \\\n",
    "  --one_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QH5k4AUNE27"
   },
   "source": [
    "Each individual upload has a unique experiment ID. This means that if you start a new upload with the same directory, you will get a new experiment ID. You can view all your uploaded experiments at https://tensorboard.dev/experiments/. Alternatively, you can list your experiments in the terminal using the following command:\n",
    "```\n",
    "tensorboard dev list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2Pj3RQCNQvP"
   },
   "outputs": [],
   "source": [
    "!tensorboard dev list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyJsD3Ypyx6m"
   },
   "source": [
    "### Screenshots of TensorBoard.dev\n",
    "\n",
    "This is what it will look like when you navigate to https://tensorboard.dev/experiments/:\n",
    "\n",
    "![screenshot of TensorBoard.dev experiment list](images/tbdev_experiment_list.png \"TensorBoard.dev experiment list screenshot\")\n",
    "\n",
    "This is what it will look like when you navigate to your new experiment on TensorBoard.dev:\n",
    "\n",
    "![screenshot of TensorBoard.dev experiment dashboard](images/tbdev_getting_started.png \"TensorBoard.dev experiment dashboard screenshot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcZOGmjQNWk_"
   },
   "source": [
    "### Deleting your TensorBoard.dev experiment\n",
    "\n",
    "To remove an experiment you have uploaded, use the `delete` command and specify the appropriate `experiment_id`.\n",
    "In the above screenshot, the experiment_id is listed in the bottom left corner: `w1lkBAOrR4eH35Y7Lg1DQQ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSkJTT9rNWJq"
   },
   "outputs": [],
   "source": [
    "# You must replace YOUR_EXPERIMENT_ID with the value output from the previous\n",
    "# tensorboard `list` command or `upload` command.  For example\n",
    "# `tensorboard dev delete --experiment_id pQpJNh00RG2Lf1zOe9BrQA`\n",
    "\n",
    "## !tensorboard dev delete --experiment_id YOUR_EXPERIMENT_ID_HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tbdev_getting_started.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
